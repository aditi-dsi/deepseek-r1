# A Step-by-Step Guide to Install DeepSeek-R1 Locally with Ollama, vLLM or Transformers
DeepSeek-R1 is s a powerful open-source reasoning model, offering advanced capabilities that challenge industry leaders like OpenAI’s o1. This model is built on a Mixture of Experts (MoE) architecture and features a whopping 671 billion parameters while efficiently activating only 37 billion during each forward pass. This approach helps balance performance and efficiency, and makes this model highly scalable and cost-effective. What sets DeepSeek-R1 apart is its unique reinforcement learning (RL) methodology, which enables it to develop chain-of-thought reasoning, self-verification, and reflection autonomously. These qualities make it an exceptional tool for tackling complex challenges across diverse fields like math, coding, and logical reasoning.
<br>
<br>
![image](https://github.com/user-attachments/assets/2cccc2a0-f7cf-4a7d-ac12-8b73029278ed)

# Installation Process
For step-by-step process of installing DeepSeek-R1, checkout my guide here: https://nodeshift.com/blog/a-step-by-step-guide-to-install-deepseek-r1-locally-with-ollama-vllm-or-transformers-2.
<br>
<br>
## What's inside the Guide?
- ✅ How to select & deploy the right GPU configuration for different models types within DeepSeek-R1
- ✅ Three distinct methods to run DeepSeek-R1 with Ollama, vLLM, or Transformers.
- ✅ Step-by-step process for each method along with model inference.
<br>
For the section "Installation using Transformers" you may follow my Python notebook alongside the guide for code simulations.
<a target="_blank" href="https://colab.research.google.com/github/aditi-dsi/deepseek-r1/blob/main/DeepSeek_R1_Distill_Qwen_1.5B.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>
